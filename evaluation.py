import os
import glob
import pylab
import pandas as pd
import numpy as np
from sklearn.metrics import roc_curve, auc

import common

def compute_Weighted_AUC(y_true, y_score, weight_distribution=np.arange(4, -1, -1.0)):
    """Compute Weighted AUC.
    
    Parameters:
    y_true -- Array, shape = [n_samples]. True binary labels in range {0, 1}.
    y_score -- Array, shape = [n_samples]. The probability estimates of the positive class.
    weight_distribution -- List, shape = [n_weights]. The weights of different areas.
    
    Returns:
    score -- Float number. The Weighted AUC score.
    """

    def perform_interpolation(fpr, tpr, threshold_array):
        """Perform interpolation.
        
        Parameters:
        fpr -- Array, shape = [n_points]. False positive rate.
        tpr -- Array, shape = [n_points]. True positive rate.
        threshold_array -- Array, shape = [n_thresholds]. The thresholds where interpolation is needed.
        
        Returns:
        result -- Tuple. The interpolated (fpr, tpr).
        """
        for threshold in threshold_array:
            # The threshold is aleady in tpr. No need to interpolate.
            if np.sum(tpr == threshold) > 0:
                continue

            """
            The threshold is not in tpr.
            Find the index which meets tpr[previous_index] < threshold and tpr[previous_index+1] > threshold.
            """
            previous_index = np.max(np.argwhere(tpr < threshold))
            following_index = previous_index + 1

            """
            Insert the interpolated data to tpr and fpr.
            The interpolated data is generated by using linear interpolation.
            """
            value = (threshold - tpr[previous_index]) * (fpr[following_index] - fpr[previous_index]) / \
                (tpr[following_index] - tpr[previous_index]) + fpr[previous_index]
            tpr = np.insert(tpr, following_index, threshold)
            fpr = np.insert(fpr, following_index, value)

        return (fpr, tpr)

    # Divide the range [0, 1] evenly
    weight_num = weight_distribution.shape[0]
    evenly_spaced_thresholds = np.linspace(0, 1, num=weight_num + 1)

    # Compute ROC curve and perform interpolation
    fpr, tpr, _ = roc_curve(y_true, y_score)
    fpr, tpr = perform_interpolation(fpr, tpr, evenly_spaced_thresholds[1:-1])

    # Plot ROC curve
    # pylab.figure()
    # pylab.plot(fpr, tpr)
    # pylab.axis("equal")
    # pylab.grid()
    # pylab.xlabel("False Positive Rate")
    # pylab.ylabel("True Positive Rate")
    # pylab.title("ROC Curve")
    # pylab.show()

    # Compute the areas
    area_array = np.zeros(weight_num)
    lowest_record_index = 0
    for area_index in range(weight_num):
        # Compute the highest index of the records within current area
        high_threshold = evenly_spaced_thresholds[area_index + 1]
        highest_record_index = np.sum(tpr <= high_threshold) - 1

        # Select the records within current area
        selected_fpr = fpr[lowest_record_index:highest_record_index + 1]
        selected_tpr = tpr[lowest_record_index:highest_record_index + 1]

        # Remove bias in True Positive Rate
        selected_tpr = selected_tpr - selected_tpr[0]

        # Extend the curve to the range [0, 1]
        selected_fpr = np.hstack(([0], selected_fpr, [1]))
        selected_tpr = np.hstack((selected_tpr[0], selected_tpr, selected_tpr[-1]))

        # Plot selected ROC curve
        # pylab.figure()
        # pylab.plot(selected_fpr, selected_tpr)
        # pylab.axis("equal")
        # pylab.grid()
        # pylab.xlabel("False Positive Rate")
        # pylab.ylabel("True Positive Rate")
        # pylab.title("Selected ROC Curve")
        # pylab.show()

        # Compute current area
        area_array[area_index] = auc(selected_fpr, selected_tpr, reorder=True)

        # Update lowest_record_index
        lowest_record_index = highest_record_index

    # Normalize weight distribution and return final score
    weight_distribution = weight_distribution / np.mean(weight_distribution)
    return np.sum(np.multiply(area_array, weight_distribution))

def perform_evaluation():
    # Read GroundTruth file
    groundtruth_file_path = os.path.join(common.SUBMISSIONS_FOLDER_PATH, common.GROUNDTRUTH_FILE_NAME)
    groundtruth_file_content = pd.read_csv(groundtruth_file_path, skiprows=0).as_matrix()
    groundtruth_label = groundtruth_file_content[:, 1]
    groundtruth_label = groundtruth_label.astype(np.float64)

    # List all csv files in current folder and evaluate them
    submission_file_path_list = glob.glob(os.path.join(common.SUBMISSIONS_FOLDER_PATH, "*.csv"))
    for submission_file_path in submission_file_path_list:
        if submission_file_path == groundtruth_file_path:
            continue

        # Read current submission file
        submission_file_content = pd.read_csv(submission_file_path, skiprows=0).as_matrix()
        submission_label = submission_file_content[:, 1]

        # Compute Weighted AUC of current submission file
        score = compute_Weighted_AUC(groundtruth_label, submission_label)
        print "%s achieved %.5f." % (os.path.basename(submission_file_path), score)

def combine_submissions(selected_submission_file_name_list):
    """Combine submissions.
    
    Parameters:
    selected_submission_file_name_list -- List, shape = [n_files]. The file names of the selected submission files.
    
    Returns:
    None. The new submission file will be created.
    """

    def get_ranks(input_array):
        """Get the ranks of items in an array.
        
        Parameters:
        input_array -- Array, shape = [n_points].
        
        Returns:
        result -- Array, shape = [n_points]. The ranks of items in an array.
        """
        order = input_array.argsort()
        ranks = order.argsort()
        return ranks

    # Read selected submission files
    selected_submission_ranks_list = []
    for selected_submission_file_name in selected_submission_file_name_list:
        selected_submission_file_path = os.path.join(common.SUBMISSIONS_FOLDER_PATH, selected_submission_file_name)
        selected_submission_file_content = pd.read_csv(selected_submission_file_path, skiprows=0).as_matrix()
        selected_submission_label = selected_submission_file_content[:, 1]
        selected_submission_ranks = get_ranks(selected_submission_label)
        selected_submission_ranks_list.append(selected_submission_ranks)
    selected_submission_ranks_array = np.array(selected_submission_ranks_list)

    # Generate mean submission file
    mean_submission = np.mean(selected_submission_ranks_array, axis=0)
    mean_submission_file_content = pd.DataFrame({"Id": np.arange(mean_submission.shape[0]), "Prediction": mean_submission})
    mean_submission_file_content.to_csv(os.path.join(common.SUBMISSIONS_FOLDER_PATH, "mean_submission.csv"), index=False, header=True)

    # Generate median submission file
    median_submission = np.median(selected_submission_ranks_array, axis=0)
    median_submission_file_content = pd.DataFrame({"Id": np.arange(median_submission.shape[0]), "Prediction": median_submission})
    median_submission_file_content.to_csv(os.path.join(common.SUBMISSIONS_FOLDER_PATH, "median_submission.csv"), index=False, header=True)

if __name__ == "__main__":
    # combine_submissions(["01_nobody.csv", "02_chenriwei.csv", "Aurora.csv"])
    perform_evaluation()
